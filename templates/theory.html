{% extends 'base.html' %}

{% load static %}

{% block title %}Theory: Huffman Coding{% endblock %}

{% block page_title %}Understanding Huffman Code{% endblock %}

{% block content %}
<div class="row fade-in">
    <div class="col-lg-12">
        <div class="card mb-4">
            <div class="card-header bg-primary text-white">
                <h4 class="mb-0">Theory</h4>
            </div>
            <div class="card-body">
                <h4 class="mb-3"><i class="fas fa-question-circle me-2"></i>What is Huffman coding?</h4>
                <p>Huffman coding is a popular lossless Variable Length Coding (VLC) scheme, based on the following principles:</p>
                <ul class="list-group list-group-flush mb-4">
                    <li class="list-group-item bg-transparent">Shorter code words are assigned to more probable symbols and longer code words are assigned to less probable symbols.</li>
                    <li class="list-group-item bg-transparent">No code word of a symbol is a prefix of another code word.</li>
                    <li class="list-group-item bg-transparent">This makes Huffman coding uniquely decodable.</li>
                    <li class="list-group-item bg-transparent">Every source symbol must have a unique code word assigned to it.</li>
                </ul>
                
                <div class="text-center my-4">
                    <img src="{% static 'images/huffman.PNG' %}" alt="Huffman coding example" class="img-fluid shadow-sm rounded">
                </div>
                
                <h4 class="mt-4 mb-3"><i class="fas fa-list-ol me-2"></i>Steps for Huffman coding:</h4>
                <ol class="list-group list-group-numbered mb-4">
                    <li class="list-group-item">List the given source of symbols in order of their specified decreasing probability.</li>
                    <li class="list-group-item">Assign a binary logic '0' and '1' to the two source symbols of lowest probability in the list obtained in above step. <em>(There are two types of Huffman coding Type-I and Type-II)</em></li>
                    <li class="list-group-item">In Type-II, we assign 1 to the symbol of lowest probability and 0 to the symbol with probability greater than it. Here, Type-I is implemented which works according to point 2.</li>
                    <li class="list-group-item">Add the probability of these two source symbols and regard it as one new source symbol. This result into reduction of the size of the list of source symbols by 1.</li>
                    <li class="list-group-item">Place the assigned probability of the new symbol, high or low in the list with the rest of symbols, with their given probabilities.</li>
                    <li class="list-group-item">While putting the probabilities, in case of same probabilities the probability obtained by adding the lowest probabilities will be placed first.</li>
                    <li class="list-group-item">Repeat the procedure specified in steps from 2 to 4, till final set of 2 source symbols is obtained.</li>
                    <li class="list-group-item">Assign binary logic 0 & 1 to the final two source symbols and all obtained symbols in step 5.</li>
                    <li class="list-group-item">Determine Codeword for each original source symbol by working backward and tracing the sequence of binary logic values.</li>
                </ol>
                
                <div class="alert alert-info">
                    <h5 class="alert-heading"><i class="fas fa-info-circle me-2"></i>Note:</h5>
                    <ul class="mb-0">
                        <li>To calculate huffman code of a string, calculate the probability of occurrence of each character and follow the steps above.</li>
                        <li>For example, if the given string is 'aabbbc' then probability of occurrence of a character: (frequency of character)/(length of string)</li>
                        <li>In 'aabbbc', probability of occurrence of a is: 2/6=0.3 as 'a' occurs twice and length of string is 6</li>
                        <li>Similarly probabilities of other distinct characters can be calculated and it should be noted that their sum equals 1.</li>
                        <li>If frequency of characters is given, then probability of occurrence = character frequency/length of string</li>
                    </ul>
                </div>
                
                <h4 class="mt-4 mb-3"><i class="fas fa-cogs me-2"></i>Properties of Huffman coding:</h4>
                <ul class="list-group list-group-flush">
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>Huffman Coding is a famous Greedy Algorithm.</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>It is used for the lossless compression of data.</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>It uses variable length encoding.</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>It assigns variable length code to all the characters.</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>The code length of a character depends on how frequently it occurs in the given text.</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-check text-success me-2"></i>The length of the character code is inversely proportional to it's probability of occurrence.</li>
                </ul>
            </div>
        </div>
    </div>
</div>
{% endblock %}